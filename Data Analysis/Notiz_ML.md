# Einteilung 
- Unsupervised Learning 
	- Strukturen, Gruppen erkennen 
	- **Methoden** : [[Notiz_Clustering#Clustering|Clustering]], [[Notiz_Assoziationsanalyse#Assoziationsanalyse|Assoziationsanalyse]] 
	- Einschub: [[Notiz_PCA#PCA|PCA]] 
	- Bewertung nur bei bekannten Daten 
- Supervised Learning 
	- Zusammenhänge lernen $\Rightarrow$ Vorhersagen 
	- **Methoden** 
		- [[Notiz_Regressionsmethoden#Regressionsmethoden|Regressionsmethoden]] 
		- [[Notiz_Klassifikationsmethoden#Klassifikationsmethoden|Klassifikationsmethoden]] 
		- [[Notiz_Methoden für Klassifikation und Regression#Methoden für Klassifikation und Regression|Methoden für Klassifikation und Regression]] 
	- Bewertung 
		- Regression 
			- Mittlerer absoluter Fehler (engl. Mean Absolute Error, MAE) 
				- $\mathrm{MAE}=\frac{1}{n} \sum_{i=1}^{n}\left|y_{i}-\hat{y}_{i}\right|$ 
			- Mittlerer quadratischer Fehler (engl. Mean Squared Error, MSE) 
				- $\operatorname{MSE}=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}$ 
			- Wurzel des mittleren quadratischen Fehlers (engl. Root Mean Squared Error, RMSE) 
				- $\mathrm{RMSE}=\sqrt{\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}$ 
			- Bestimmtheitsmaß ($R^{2}-Score$) 
				- ein Maß dafür, wie gut die beobachteten Ergebnisse durch das Modell erklärt werden. 
				- $R^{2}=1-\frac{\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}}{\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}}$ 
		- Klassifikation 
			- <img src="https://github.com/ICH-BIN-HXM/images_DAAN/blob/main/Scrennshot_2024-07-07_13-25-00.png?raw=" width="40%" /> 
			- Genauigkeit (engl. Accuracy) $=\frac{\sum \mathrm{TP}+\mathrm{TN}}{\sum \mathrm{TP}+\mathrm{FP}+\mathrm{FN}+\mathrm{TN}}$ 
			- Relevanz (engl. Precision) 
				- <img src="https://github.com/ICH-BIN-HXM/images_DAAN/blob/main/Scrennshot_2024-07-07_13-34-11.png?raw=" width="40%" /> 
				- $=\frac{\sum \mathrm{TP}}{\sum \mathrm{TP}+\mathrm{FP}}$ 
			- Sensitivität (engl. Recall) 
				- <img src="https://github.com/ICH-BIN-HXM/images_DAAN/blob/main/Scrennshot_2024-07-07_13-34-10.png?raw=" width="40%" /> 
				- $=\frac{\sum \mathrm{TP}}{\sum \mathrm{TP}+\mathrm{FN}}$ 
			- F1-Score 
				- ein harmonisches Mittel zwischen Präzision und Recall 
				- $=2 \times \frac{\text { Precision } \times \text { Recall }}{\text { Precision }+ \text { Recall }}$ 
			- AUC-ROC (Area Under the Receiver Operating Characteristic Curve) 
				- True Positive Rate (Recall) vs. False Positive Rate (FPR, $\frac{\sum \mathrm{FP}}{\sum \mathrm{FP} + \mathrm{TN}}$) 
			- AUC-PR (Area Under the Precision-Recall Curve) 
				- Precision-Recall-Kurve 
			- Loss-Funktion 