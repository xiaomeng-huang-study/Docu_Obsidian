# Probleme 
- Overfitting 
	- Definition 
		- ein Modell während des Trainings zu gut auf die Trainingsdaten passt, aber Schwierigkeiten hat, auf neuen, nicht gesehenen Daten zu generalisieren 
	- Lösung 
		- Dropout-Layer 
		- Augmentierung 
- Vanishing Gradients 
	- Definition 
		- die Gradienten der Verlustfunktion, die durch den Backpropagation-Algorithmus berechnet werden, in den tiefen Schichten des Netzwerks extrem klein werden. (Dies kann dazu führen, dass die Gewichtungen in diesen Schichten nicht effektiv aktualisiert werden, was das Training schwierig oder sogar unmöglich macht.) 
	- Lösungen 
		- [[Notiz_Kapitel_1#^aktivierungsfunktion|ReLU-Aktivierungsfunktion]] verwenden 
		- [[Notiz_Kapitel_2_CNN_Einschube#Batch Normalization|Batch-Normalization]] 
- Rausch 
	- Schwankung 
	- Lösung 
		- [[Notiz_Kapitel_2_CNN_Einschube#Anpassung der Learning Rate|Anpassung der Learning Rate]] 